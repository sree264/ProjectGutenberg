{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading a text file\n",
    "file_raw = open(\"1342.txt\",\"r\", encoding=\"utf8\") \n",
    "# print(file_raw.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edited text file without author's notes in the start and end\n",
    "import string\n",
    "file_edited = open(\"1342_edited.txt\",\"r\", encoding=\"utf8\") \n",
    "#remove \\n from the whole text\n",
    "file_edited_read = file_edited.read().replace('\\n', ' ')\n",
    "# print(file_edited_read)\n",
    "\n",
    "#remove punctuation \n",
    "# # initializing punctuations string   \n",
    "punctuations = '''!()-[]{};:'\"”“\\,<>./?@#$%^&*_~''' \n",
    "for x in file_edited_read: \n",
    "    if x in punctuations: \n",
    "        file_edited_read = file_edited_read.lower().replace(x, \"\")  \n",
    "print(file_edited_read)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting text (novel) to chapters for further use\n",
    "list_chapters = file_edited_read.split('chapter ')[1:]\n",
    "# print(list_chapters[59], list_chapters[58])\n",
    "for i in range(0, len(list_chapters)):\n",
    "    a =  list_chapters[i].lstrip('0123456789.- ')\n",
    "    #remove \\n or new line\n",
    "    list_chapters[i] = a.replace('\\n','')\n",
    "    punctuations = '''!()-[]{};:'\"”“\\,<>./?@#$%^&*_~''' \n",
    "    punctuations_dotted = '''!()-[]{};:'\"”“\\,<>/?@#$%^&*_~'''\n",
    "for i in range(0, len(list_chapters)):\n",
    "    for x in list_chapters[i]: \n",
    "        if x in punctuations: \n",
    "            list_chapters[i] = list_chapters[i].lower().replace(x, \"\")   \n",
    "    \n",
    "print(list_chapters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating text file for 1000 words and reading into list\n",
    "def common_words_breakpoint(count):\n",
    "    with open(\"common_words_1000.txt\") as file_in:\n",
    "        common_words = []\n",
    "        for line in file_in:\n",
    "            count = count - 1\n",
    "            if count == -1:\n",
    "                break\n",
    "            common_words.append(line.replace('\\n',''))\n",
    "    return common_words\n",
    "# common_words_breakpoint(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method1: number of words in the whole text using COUNTER\n",
    "def getTotalNumberOfWords(string):\n",
    "    count = 0\n",
    "    dictionary = Counter(string.split())\n",
    "    for key, value in dictionary.items():\n",
    "        if value>=1:\n",
    "            count += value\n",
    "    print(count)\n",
    "getTotalNumberOfWords(file_edited_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method2: number of unique words in the whole text using COUNTER:\n",
    "def getTotalUniqueWords(string):\n",
    "    word_list = []\n",
    "    dictionary = Counter(string.split())\n",
    "    for key, value in dictionary.items():\n",
    "        if value>=1:\n",
    "            word_list.append(key)\n",
    "    print(len(word_list))\n",
    "getTotalUniqueWords(file_edited_read)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method3: 20 most frequent words in the whole text using COUNTER:\n",
    "def getMostFrequentWords(string):\n",
    "    word_list = []\n",
    "    dictionary = Counter(string.split())\n",
    "    sorted_counter = dictionary.most_common(20)\n",
    "    print(sorted_counter)\n",
    "getMostFrequentWords(file_edited_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Methode4:\n",
    "def getMostInterestingFrequentWords(string, tune_point):\n",
    "\n",
    "    word_list = []\n",
    "    dictionary = Counter(string.split())\n",
    "    sorted_counter = dictionary.most_common()\n",
    "    #breaing point as 100\n",
    "    common_list = common_words_breakpoint(tune_point)\n",
    "    for (key, val) in sorted_counter:\n",
    "#         print(common_list)\n",
    "        if key not in common_list:\n",
    "            word_list.append(key)\n",
    "    print(len(word_list))\n",
    "            \n",
    "getMostInterestingFrequentWords(file_edited_read, 100)\n",
    "getMostInterestingFrequentWords(file_edited_read, 200)\n",
    "getMostInterestingFrequentWords(file_edited_read, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method3: 20 most frequent words in the whole text using COUNTER:\n",
    "def getMostFrequentWords(string):\n",
    "    word_list = []\n",
    "    dictionary = Counter(string.split())\n",
    "    sorted_counter = dictionary.most_common()[:-20-1:-1]\n",
    "    print(sorted_counter)\n",
    "getMostFrequentWords(file_edited_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP3: get frequncy of words for each chapter in a list\n",
    "def getFrequencyOfWord(word):\n",
    "    result = []\n",
    "    for i in list_chapters:\n",
    "        temp = 0\n",
    "        dictionary = Counter(i.split())\n",
    "        for key, value in dictionary.items():\n",
    "            if key == word:\n",
    "                temp = value\n",
    "        result.append(temp)       \n",
    "    return result       \n",
    "print(getFrequencyOfWord('this'))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "def getChapterQuoteAppears(string):\n",
    "    for x in string: \n",
    "        if x in punctuations: \n",
    "            string = string.lower().replace(x, \"\")\n",
    "#     print(string)\n",
    "    for i in range(0, len(list_chapters)):\n",
    "        if string in list_chapters[i]:\n",
    "            return i+1\n",
    "    return -1 \n",
    "string = \"Mr. Darcy bowed\"\n",
    "print(getChapterQuoteAppears(string))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edited text file without author's notes in the start and end\n",
    "import string\n",
    "file_edited_sent = open(\"1342_edited.txt\",\"r\", encoding=\"utf8\") \n",
    "#remove \\n from the whole text\n",
    "file_edited_read_sent = file_edited_sent.read().replace('\\n', ' ')\n",
    "# print(file_edited_read)\n",
    "\n",
    "#remove punctuation \n",
    "# # initializing punctuations string without deleting full stop (tokenize sentences . is required)   \n",
    "punctuations_dotted = '''!()-[]{};:'\"”“\\,<>./?@#$%^&*_~''' \n",
    "for x in file_edited_read_sent: \n",
    "    if x in punctuations_dotted: \n",
    "        file_edited_read_sent = file_edited_read_sent.lower().replace(x, \"\")  \n",
    "print(file_edited_read_sent)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLTK TO TOKENISE THE TEXT TO SENTENCES\n",
    "from nltk import tokenize\n",
    "print(tokenize.sent_tokenize(file_edited_read_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
